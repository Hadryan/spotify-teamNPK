{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "final = pd.read_csv(\"../raw_data/track_meta_milestone3.csv\", index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_new = final[['Playlistid', 'Trackid', 'Artist_Name', 'Track_uri',\n",
    "                   'Track_Name', 'Album_Name', 'Track_Duration',\n",
    "                   'acousticness', 'artist_genres', 'artist_popularity',\n",
    "                   'danceability', 'energy', 'instrumentalness', 'key',\n",
    "                   'liveness', 'loudness', 'mode', 'speechiness', 'tempo',\n",
    "                   'time_signature', 'valence', 'Track', 'Artist']] #keep columns of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train-Test Split\n",
    "# Train-val-test split (20%)\n",
    "train, test = train_test_split(final_new, test_size=0.2, random_state=48, stratify = final_new['Playlistid'])\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=48, stratify = train['Playlistid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['index'] = np.arange(1, len(train)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Features for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleCols = ['acousticness', 'danceability', 'energy', 'instrumentalness',\n",
    "             'key', 'liveness', 'loudness', 'speechiness', 'tempo','valence', 'time_signature', 'artist_popularity'] #mode excluded from analysis\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train.loc[:, scaleCols])\n",
    "train_scaled = train.copy() #copy original master data frame\n",
    "train_scaled[scaleCols] = scaler.transform(train_scaled[scaleCols]) #scale transform cluster columns\n",
    "train_scaled['index'] = np.arange(1, len(train_scaled)+1) #reappend index column\n",
    "train_scaled = train_scaled.rename(columns = {'acousticness': 'acousticness_scaled',\n",
    "                                              'danceability': 'danceability_scaled',\n",
    "                                              'energy': 'energy_scaled',\n",
    "                                              'instrumentalness': 'instrumentalness_scaled',\n",
    "                                              'key': 'key_scaled',\n",
    "                                              'liveness': 'liveness_scaled',\n",
    "                                              'loudness': 'loudness_scaled',\n",
    "                                              'speechiness': 'speechiness_scaled',\n",
    "                                              'tempo': 'tempo_scaled',\n",
    "                                              'valence': 'valence_scaled',\n",
    "                                              'time_signature': 'time_signature_scaled',\n",
    "                                              'artist_popularity': 'artist_popularity_scaled'})\n",
    "joinCols = ['index', 'Playlistid', 'Trackid', 'Track_uri', 'Artist_Name',\n",
    "            'Track_Name', 'Album_Name', 'Track_Duration', \n",
    "            'artist_genres', 'mode']\n",
    "train_new = train.merge(train_scaled, on = joinCols, how = 'outer') #merge scaled data with original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate clusters\n",
    "def makeCluster(df, n, rs, cols):\n",
    "    '''\n",
    "    Parameters:\n",
    "    1) df: master data frame\n",
    "    2) n: number of clusters\n",
    "    3) rs: random state\n",
    "    4) cols: list of clustering variables\n",
    "    '''\n",
    "    #copy dataframe\n",
    "    dfCluster = df.copy()\n",
    "\n",
    "    #fit clusters\n",
    "    kmeans = KMeans(n_clusters = n, random_state = rs)\n",
    "    kmeans.fit(dfCluster.loc[:, cols])\n",
    "\n",
    "    #get location of cluster centroids and label\n",
    "    center = kmeans.cluster_centers_\n",
    "    label = kmeans.labels_\n",
    "    dfCluster['cluster_label'] = label\n",
    "    dfCluster['cluster_label'] = dfCluster['cluster_label'] + 1 #increment by 1 so 0 implies non-existence in prediction\n",
    "    \n",
    "    #append centroids to data frame\n",
    "    centroids = defaultdict(list)\n",
    "    for col in cols:\n",
    "        centroids['columns'].append(col)\n",
    "    for a in range(len(center)):\n",
    "        for b in range(len(center[0])):\n",
    "            centroids['c'+ str(a)].append(center[a][b])\n",
    "            dfCluster['c'+ str(a) + cols[b]] = center[a][b]\n",
    "\n",
    "    return dfCluster, pd.DataFrame.from_dict(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterCols = ['acousticness_scaled','danceability_scaled', \n",
    "               'energy_scaled', 'instrumentalness_scaled',\n",
    "               'key_scaled', 'liveness_scaled', 'loudness_scaled',\n",
    "               'speechiness_scaled', 'tempo_scaled', 'time_signature_scaled',\n",
    "               'valence_scaled'] #variables to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train cluster\n",
    "train_cluster, train_centroids = makeCluster(train_new, 8, 48, clusterCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank centroids\n",
    "def rankC(dfCentroid, n):\n",
    "    rankC = defaultdict(list)\n",
    "    for i in range(n):\n",
    "        rankC['cluster'].append(i)\n",
    "        for j in range(n):\n",
    "            rankC[str(j)].append(euclidean(dfCentroid['c'+str(i)], dfCentroid['c'+str(j)]))    \n",
    "    rankC = pd.DataFrame(rankC)\n",
    "    orderRankC = defaultdict(list)\n",
    "    for i in range(n):\n",
    "        orderRankC[str(i)] = rankC[str(i)].sort_values(ascending = True).index.values\n",
    "    return orderRankC\n",
    "\n",
    "orderRankc = rankC(train_centroids, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize prediction cluster\n",
    "prediction_cluster = train_cluster[['Playlistid', 'Trackid', 'Track_uri', 'Artist_Name', 'Track_Name',\n",
    "                                   'artist_genres','artist_popularity', 'cluster_label', 'Track_x', 'Artist_x']].rename(columns = {'Track_x':'Track',\n",
    "                                                                                                                                   'Artist_x':'Artist'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the times an artist appears in one cluster\n",
    "mode_artist = prediction_cluster.groupby(['cluster_label', 'Artist_Name'])['Playlistid'].count().reset_index()\n",
    "mode_artist = mode_artist.rename(columns = {'Playlistid': 'mode_artist'})\n",
    "prediction_cluster = prediction_cluster.merge(mode_artist, on = ['cluster_label', 'Artist_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the times a track appears in one cluster\n",
    "mode_track = prediction_cluster.groupby(['cluster_label', 'Track_Name'])['Playlistid'].count().reset_index()\n",
    "mode_track = mode_track.rename(columns = {'Playlistid': 'mode_track'})\n",
    "prediction_cluster = prediction_cluster.merge(mode_track, on = ['cluster_label', 'Track_Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import predict_cluster\n",
    "import predict_cluster_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_precision(prediction, val_set):\n",
    "# prediction should be a list of predictions\n",
    "# val_set should be pandas Series of ground truths\n",
    "    score = np.sum(val_set.isin(prediction))/val_set.shape[0]\n",
    "    return score\n",
    "\n",
    "### NDCG Code Source: https://gist.github.com/bwhite/3726239\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27016"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.Playlistid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/Spotify_Project/spotify-teamNPK/src/predict_cluster_updated.py\u001b[0m in \u001b[0;36mcPredict\u001b[0;34m(dfCluster, playlist_id, clusterRank, df)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0muri\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_uri\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0muri\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracks\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muri\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                     \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-df98ef93abf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_cluster_updated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcPredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_cluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morderRankc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlaylistid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrack_uri\u001b[0m \u001b[0;31m# ground truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrps_updated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Spotify_Project/spotify-teamNPK/src/predict_cluster_updated.py\u001b[0m in \u001b[0;36mcPredict\u001b[0;34m(dfCluster, playlist_id, clusterRank, df)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mpred_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrankTrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrack_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0muri\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_uri\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0muri\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracks\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muri\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#test check\n",
    "rps_updated = []\n",
    "ndcgs_updated = []\n",
    "count = 1\n",
    "for pid in test.Playlistid.unique():\n",
    "    #track progress\n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "    ps = predict_cluster_updated.cPredict(prediction_cluster, pid, orderRankc, test) # predictions\n",
    "    vs = test[test.Playlistid == pid].Track_uri # ground truth\n",
    "    rps_updated.append(r_precision(ps, vs))\n",
    "    \n",
    "    r = np.zeros(len(ps))\n",
    "    for i, p in enumerate(ps):\n",
    "        if np.any(vs.isin([p])):\n",
    "            r[i] = 1\n",
    "    ndcgs_updated.append(ndcg_at_k(r, len(r)))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
