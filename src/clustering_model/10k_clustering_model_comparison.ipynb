{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages for clustering\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "final = pd.read_csv(\"../raw_data/track_meta_milestone3.csv\", index_col=\"Unnamed: 0\")\n",
    "\n",
    "final_new = final[['Playlistid', 'Trackid', 'Artist_Name', 'Track_uri',\n",
    "                   'Track_Name', 'Album_Name', 'Track_Duration',\n",
    "                   'acousticness', 'artist_genres', 'artist_popularity',\n",
    "                   'danceability', 'energy', 'instrumentalness', 'key',\n",
    "                   'liveness', 'loudness', 'mode', 'speechiness', 'tempo',\n",
    "                   'time_signature', 'valence', 'Track', 'Artist']] #keep columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "subset10k = np.random.choice(final_new.Playlistid.unique(), size = 10000, replace = False) #randomly select 1000 playlist ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10k = final_new[final_new.Playlistid.isin(subset10k)] #subset 10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df10k.Playlistid.unique()) #check if 10k unique playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train-Test Split\n",
    "# Train-val-test split (20%)\n",
    "train, test = train_test_split(df10k, test_size=0.2, random_state=48, stratify = df10k['Playlistid'])\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=48, stratify = train['Playlistid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['index'] = np.arange(1, len(train)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Features for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleCols = ['acousticness', 'danceability', 'energy', 'instrumentalness',\n",
    "             'key', 'liveness', 'loudness', 'speechiness', 'tempo','valence', 'time_signature', 'artist_popularity'] #mode excluded from analysis\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train.loc[:, scaleCols])\n",
    "train_scaled = train.copy() #copy original master data frame\n",
    "train_scaled[scaleCols] = scaler.transform(train_scaled[scaleCols]) #scale transform cluster columns\n",
    "train_scaled['index'] = np.arange(1, len(train_scaled)+1) #reappend index column\n",
    "train_scaled = train_scaled.rename(columns = {'acousticness': 'acousticness_scaled',\n",
    "                                              'danceability': 'danceability_scaled',\n",
    "                                              'energy': 'energy_scaled',\n",
    "                                              'instrumentalness': 'instrumentalness_scaled',\n",
    "                                              'key': 'key_scaled',\n",
    "                                              'liveness': 'liveness_scaled',\n",
    "                                              'loudness': 'loudness_scaled',\n",
    "                                              'speechiness': 'speechiness_scaled',\n",
    "                                              'tempo': 'tempo_scaled',\n",
    "                                              'valence': 'valence_scaled',\n",
    "                                              'time_signature': 'time_signature_scaled',\n",
    "                                              'artist_popularity': 'artist_popularity_scaled'})\n",
    "joinCols = ['index', 'Playlistid', 'Trackid', 'Track_uri', 'Artist_Name',\n",
    "            'Track_Name', 'Album_Name', 'Track_Duration', \n",
    "            'artist_genres', 'mode']\n",
    "train_new = train.merge(train_scaled, on = joinCols, how = 'outer') #merge scaled data with original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate clusters\n",
    "def makeCluster(df, n, rs, cols):\n",
    "    '''\n",
    "    Parameters:\n",
    "    1) df: master data frame\n",
    "    2) n: number of clusters\n",
    "    3) rs: random state\n",
    "    4) cols: list of clustering variables\n",
    "    '''\n",
    "    #copy dataframe\n",
    "    dfCluster = df.copy()\n",
    "\n",
    "    #fit clusters\n",
    "    kmeans = KMeans(n_clusters = n, random_state = rs)\n",
    "    kmeans.fit(dfCluster.loc[:, cols])\n",
    "\n",
    "    #get location of cluster centroids and label\n",
    "    center = kmeans.cluster_centers_\n",
    "    label = kmeans.labels_\n",
    "    dfCluster['cluster_label'] = label\n",
    "    dfCluster['cluster_label'] = dfCluster['cluster_label'] + 1 #increment by 1 so 0 implies non-existence in prediction\n",
    "    \n",
    "    #append centroids to data frame\n",
    "    centroids = defaultdict(list)\n",
    "    for col in cols:\n",
    "        centroids['columns'].append(col)\n",
    "    for a in range(len(center)):\n",
    "        for b in range(len(center[0])):\n",
    "            centroids['c'+ str(a)].append(center[a][b])\n",
    "            dfCluster['c'+ str(a) + cols[b]] = center[a][b]\n",
    "\n",
    "    return dfCluster, pd.DataFrame.from_dict(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterCols = ['acousticness_scaled','danceability_scaled', \n",
    "               'energy_scaled', 'instrumentalness_scaled',\n",
    "               'key_scaled', 'liveness_scaled', 'loudness_scaled',\n",
    "               'speechiness_scaled', 'tempo_scaled', 'time_signature_scaled',\n",
    "               'valence_scaled'] #variables to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train cluster\n",
    "train_cluster, train_centroids = makeCluster(train_new, 8, 48, clusterCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank centroids\n",
    "def rankC(dfCentroid, n):\n",
    "    rankC = defaultdict(list)\n",
    "    for i in range(n):\n",
    "        rankC['cluster'].append(i)\n",
    "        for j in range(n):\n",
    "            rankC[str(j)].append(euclidean(dfCentroid['c'+str(i)], dfCentroid['c'+str(j)]))    \n",
    "    rankC = pd.DataFrame(rankC)\n",
    "    orderRankC = defaultdict(list)\n",
    "    for i in range(n):\n",
    "        orderRankC[str(i)] = rankC[str(i)].sort_values(ascending = True).index.values\n",
    "    return orderRankC\n",
    "\n",
    "orderRankc = rankC(train_centroids, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize prediction cluster\n",
    "prediction_cluster = train_cluster[['Playlistid', 'Trackid', 'Track_uri', 'Artist_Name', 'Track_Name',\n",
    "                                   'artist_genres','artist_popularity', 'cluster_label', 'Track_x', 'Artist_x']].rename(columns = {'Track_x':'Track',\n",
    "                                                                                                                                   'Artist_x':'Artist'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the times an artist appears in one cluster\n",
    "mode_artist = prediction_cluster.groupby(['cluster_label', 'Artist_Name'])['Playlistid'].count().reset_index()\n",
    "mode_artist = mode_artist.rename(columns = {'Playlistid': 'mode_artist'})\n",
    "prediction_cluster = prediction_cluster.merge(mode_artist, on = ['cluster_label', 'Artist_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the times a track appears in one cluster\n",
    "mode_track = prediction_cluster.groupby(['cluster_label', 'Track_Name'])['Playlistid'].count().reset_index()\n",
    "mode_track = mode_track.rename(columns = {'Playlistid': 'mode_track'})\n",
    "prediction_cluster = prediction_cluster.merge(mode_track, on = ['cluster_label', 'Track_Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import predict_cluster #original prediction model\n",
    "import predict_cluster_updated #tuned prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_precision(prediction, val_set):\n",
    "# prediction should be a list of predictions\n",
    "# val_set should be pandas Series of ground truths\n",
    "    score = np.sum(val_set.isin(prediction))/val_set.shape[0]\n",
    "    return score\n",
    "\n",
    "### NDCG Code Source: https://gist.github.com/bwhite/3726239\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.Playlistid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#validation check\n",
    "rps = []\n",
    "ndcgs = []\n",
    "count = 1\n",
    "for pid in val.Playlistid.unique():\n",
    "    #track progress\n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "    ps = predict_cluster.cPredict(prediction_cluster, pid, orderRankc, val) # predictions\n",
    "    vs = val[val.Playlistid == pid].Track_uri # ground truth\n",
    "    rps.append(r_precision(ps, vs))\n",
    "    \n",
    "    r = np.zeros(len(ps))\n",
    "    for i, p in enumerate(ps):\n",
    "        if np.any(vs.isin([p])):\n",
    "            r[i] = 1\n",
    "    ndcgs.append(ndcg_at_k(r, len(r)))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. R-Precision:  0.029928074931039567\n",
      "Avg. NDCG:  0.04289429582709006\n",
      "Total Sum:  0.03641118537906481\n"
     ]
    }
   ],
   "source": [
    "avg_rp = np.mean(rps)\n",
    "avg_ndcg = np.mean(ndcgs)\n",
    "print('Avg. R-Precision: ', avg_rp)\n",
    "print('Avg. NDCG: ', avg_ndcg)\n",
    "print('Total Sum: ', np.mean([avg_rp, avg_ndcg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#test check\n",
    "rps_updated = []\n",
    "ndcgs_updated = []\n",
    "count = 1\n",
    "for pid in test.Playlistid.unique():\n",
    "    #track progress\n",
    "    if count%100 == 0:\n",
    "        print(count)\n",
    "    ps = predict_cluster_updated.cPredict(prediction_cluster, pid, orderRankc, test) # predictions\n",
    "    vs = test[test.Playlistid == pid].Track_uri # ground truth\n",
    "    rps_updated.append(r_precision(ps, vs))\n",
    "    \n",
    "    r = np.zeros(len(ps))\n",
    "    for i, p in enumerate(ps):\n",
    "        if np.any(vs.isin([p])):\n",
    "            r[i] = 1\n",
    "    ndcgs_updated.append(ndcg_at_k(r, len(r)))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. R-Precision:  0.11821517705293787\n",
      "Avg. NDCG:  0.1330804266303709\n",
      "Total Sum:  0.1256478018416544\n"
     ]
    }
   ],
   "source": [
    "avg_rp_updated = np.mean(rps_updated)\n",
    "avg_ndcg_updated = np.mean(ndcgs_updated)\n",
    "print('Avg. R-Precision: ', avg_rp_updated)\n",
    "print('Avg. NDCG: ', avg_ndcg_updated)\n",
    "print('Total Sum: ', np.mean([avg_rp_updated, avg_ndcg_updated]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
